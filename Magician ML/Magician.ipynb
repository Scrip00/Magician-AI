{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d69d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.audio import Audio\n",
    "from opensoundscape.spectrogram import Spectrogram\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np \n",
    "import cv2\n",
    "import shutil\n",
    "import stat\n",
    "import keras\n",
    "\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "spec_width = 128\n",
    "spec_height = 128\n",
    "\n",
    "num_imgs = 30\n",
    "\n",
    "model = keras.models.load_model('Magician.h5')\n",
    "fr_model = keras.models.load_model('Face_recognition.h5')\n",
    "\n",
    "img_ext = [\"jpg\",\"png\", \"jpeg\"];\n",
    "sound_ext = [\"wav\"];\n",
    "ext = img_ext + sound_ext\n",
    "\n",
    "path = 'C:/Users/Scrip0/Desktop/Internships/Magician AI/MagicianDatasetApp/Data/False/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6209df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (img_width, img_height))\n",
    "    img = np.array(img) / 256.0\n",
    "    return img\n",
    "\n",
    "fr_model = keras.models.load_model('Face_recognition.h5')\n",
    "\n",
    "def load_audio(path):\n",
    "    audio = Audio.from_file(path).trim(0.05,2.05)\n",
    "    \n",
    "    spectrogram = Spectrogram.from_audio(audio)\n",
    "    \n",
    "    image = spectrogram.to_image(shape=(spec_width, spec_height),invert=False)\n",
    "\n",
    "    return np.array(image) / 256\n",
    "\n",
    "def prep_imgs(imgs):\n",
    "    length = len(imgs)\n",
    "    if (length > num_imgs):\n",
    "        n = length - num_imgs\n",
    "        i = (int)(length / (n + 1))\n",
    "        for l in range(1, n + 1):\n",
    "            imgs.pop(length - i * l)\n",
    "    elif (len(imgs) < num_imgs):\n",
    "        n =  num_imgs - length\n",
    "        i = (int)(length / (n + 1))\n",
    "        for l in range(1, n + 1):\n",
    "            imgs.insert(length - i * l, imgs[length - i * l - 1])\n",
    "    return imgs\n",
    "\n",
    "def predict(path):\n",
    "    imgs = []\n",
    "    for files in (files for files in (glob.glob(path + '/*.%s' % e) for e in ext) if files != []):\n",
    "        if (os.path.splitext(files[0])[1].split(\".\")[1] in sound_ext):\n",
    "            audio = load_audio(files[0])\n",
    "        else:\n",
    "            for img in files: \n",
    "                imgs.append(fr_model.predict(load_img(img).reshape(1, img_width, img_height, 3), verbose = 0))\n",
    "    imgs = prep_imgs(imgs)\n",
    "    imgs = np.array(imgs).reshape(1, num_imgs)\n",
    "    audio = audio.reshape(1, spec_width, spec_height)\n",
    "    return model.predict([imgs, audio], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd72600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in os.scandir(path):\n",
    "    print(predict(it.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b44ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c3fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
