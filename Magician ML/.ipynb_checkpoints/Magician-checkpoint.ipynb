{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d69d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "from opensoundscape.audio import Audio\n",
    "from opensoundscape.spectrogram import Spectrogram\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "import stat\n",
    "import keras\n",
    "\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "spec_width = 256\n",
    "spec_height = 256\n",
    "\n",
    "num_imgs = 30\n",
    "\n",
    "model = keras.models.load_model('Magician.h5')\n",
    "fr_model = keras.models.load_model('Face_recognition.h5')\n",
    "\n",
    "img_ext = [\"jpg\",\"png\", \"jpeg\"];\n",
    "sound_ext = [\"wav\"];\n",
    "ext = img_ext + sound_ext\n",
    "\n",
    "path = 'C:/Users/Scrip0/Desktop/Internships/Magician AI/MagicianDatasetApp/Data_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6209df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (img_width, img_height))\n",
    "    img = np.array(img) / 256.0\n",
    "    return img\n",
    "\n",
    "fr_model = keras.models.load_model('Face_recognition.h5')\n",
    "\n",
    "def load_audio(path):\n",
    "    audio = Audio.from_file(path).trim(0.05,2.05)\n",
    "    \n",
    "    spectrogram = Spectrogram.from_audio(audio)\n",
    "    \n",
    "    image = spectrogram.to_image(shape=(spec_width, spec_height),invert=False)\n",
    "\n",
    "    return np.array(image) / 256\n",
    "\n",
    "def prep_imgs(imgs):\n",
    "    length = len(imgs)\n",
    "    if (length > num_imgs):\n",
    "        n = length - num_imgs\n",
    "        i = (int)(length / (n + 1))\n",
    "        for l in range(1, n + 1):\n",
    "            imgs.pop(length - i * l)\n",
    "    elif (len(imgs) < num_imgs):\n",
    "        n =  num_imgs - length\n",
    "        i = (int)(length / (n + 1))\n",
    "        for l in range(1, n + 1):\n",
    "            imgs.insert(length - i * l, imgs[length - i * l - 1])\n",
    "    return imgs\n",
    "\n",
    "def predict(path):\n",
    "    imgs = []\n",
    "    for files in (files for files in (glob.glob(path + '/*.%s' % e) for e in ext) if files != []):\n",
    "        if (os.path.splitext(files[0])[1].split(\".\")[1] in sound_ext):\n",
    "            audio = load_audio(files[0])\n",
    "        else:\n",
    "            for img in files: \n",
    "                imgs.append(fr_model.predict(load_img(img).reshape(1, img_width, img_height, 3), verbose = 0))\n",
    "    imgs = prep_imgs(imgs)\n",
    "    imgs = np.array(imgs).reshape(1, num_imgs)\n",
    "    audio = audio.reshape(1, spec_width, spec_height)\n",
    "    return model.predict([imgs, audio], verbose = 0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd72600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(path):\n\u001b[0;32m      7\u001b[0m     name \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(name, pred)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m suits:\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m files: \n\u001b[0;32m     38\u001b[0m             imgs\u001b[38;5;241m.\u001b[39mappend(fr_model\u001b[38;5;241m.\u001b[39mpredict(load_img(img)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, img_width, img_height, \u001b[38;5;241m3\u001b[39m), verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 39\u001b[0m imgs \u001b[38;5;241m=\u001b[39m \u001b[43mprep_imgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(imgs)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, num_imgs)\n\u001b[0;32m     41\u001b[0m audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, spec_width, spec_height)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mprep_imgs\u001b[1;34m(imgs)\u001b[0m\n\u001b[0;32m     26\u001b[0m     i \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m)(length \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 28\u001b[0m         imgs\u001b[38;5;241m.\u001b[39minsert(length \u001b[38;5;241m-\u001b[39m i \u001b[38;5;241m*\u001b[39m l, \u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m imgs\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "suits = ['clubs', 'diamonds', 'hearts', 'spades']\n",
    "suit = ''\n",
    "suit_n = 2\n",
    "rank = ''\n",
    "rank_n = 2\n",
    "for it in os.scandir(path):\n",
    "    name = it.path.split(\"_\")[-1]\n",
    "    pred = predict(it.path)\n",
    "    print(name, pred)\n",
    "    if name in suits:\n",
    "        if (pred < suit_n):\n",
    "            suit_n = pred\n",
    "            suit = name\n",
    "    else:\n",
    "        if (pred < rank_n):\n",
    "            rank_n = pred\n",
    "            rank = name\n",
    "            \n",
    "print(rank, suit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queen of hearts test_2\n",
    "# ace of spades test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c3fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1009b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5027ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
