{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4e00a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import glob\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import MaxPooling2D, BatchNormalization, Conv2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, Rescaling\n",
    "from tensorflow.keras import Input \n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "\n",
    "width = 128\n",
    "height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "148df3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/Scrip0/Desktop/Internships/Magician AI/MagicianDatasetApp/Data\"\n",
    "ext = [\"jpg\",\"png\", \"jpeg\"];\n",
    "\n",
    "def read_img(path):\n",
    "    img = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (width, height))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5a1bb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imgs len:  510\n",
      "Labels len:  510\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "for path in glob.glob(f'{data_path + \"/True\"}/*/'):\n",
    "    for files in (files for files in (glob.glob(path + '/*.%s' % e) for e in ext) if files != []):\n",
    "        for file in files:\n",
    "            imgs.append(read_img(file))\n",
    "            labels.append(1.0)\n",
    "\n",
    "for path in glob.glob(f'{data_path + \"/False\"}/*/'):\n",
    "    for files in (files for files in (glob.glob(path + '/*.%s' % e) for e in ext) if files != []):\n",
    "        for file in files:\n",
    "            imgs.append(read_img(file))\n",
    "            labels.append(0.0)\n",
    "            \n",
    "print(\"Imgs len: \", len(imgs))\n",
    "print(\"Labels len: \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46c83d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = shuffle(imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dd74e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.array(imgs) / 256.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55d2d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels, train_size=0.8, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13c0591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 128, 128, 3)\n",
      "(102, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd0970e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=(width, height, 3))) #3 if RGB, 1 if GrayScale\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, 5, activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, 5, activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, 5, activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, 5, activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(16, 5, activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf9a0823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 64)      4864      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 64, 64, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 64, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 64)        102464    \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 32)        51232     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 16, 16, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 16, 16, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 8, 8, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 8, 8, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 8, 8, 16)          12816     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 4, 4, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 214,353\n",
      "Trainable params: 213,937\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be751839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"MeanSquaredError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eaeef028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 3s 71ms/step - loss: 0.1101 - val_loss: 0.2453\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.0635 - val_loss: 0.2081\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.0693 - val_loss: 0.1940\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.0559 - val_loss: 0.1792\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.0542 - val_loss: 0.1905\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.0518 - val_loss: 0.1847\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.0637 - val_loss: 0.2534\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.0572 - val_loss: 0.2594\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.0518 - val_loss: 0.3191\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True)\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=20, epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad143fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Face_recognition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14012178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 81ms/step\n",
      "[0.61261475 0.6080866  0.61300164 0.6013592  0.6125489  0.60969484\n",
      " 0.6080013  0.6140954  0.6123718  0.61303085 0.608053   0.6105988\n",
      " 0.60859513 0.60378456 0.6053471  0.6068632  0.61263824 0.6084306\n",
      " 0.6115178  0.61287457 0.61559206 0.6133717  0.61373067 0.606746\n",
      " 0.6056151  0.61411595 0.6121     0.60971636 0.6063653  0.6122075\n",
      " 0.6084388  0.6114573  0.6124323  0.60968596 0.6078933  0.61166465\n",
      " 0.60896456 0.611402   0.60669    0.6111899  0.61929107 0.6083842\n",
      " 0.61107945 0.60959816 0.6116034  0.61129296 0.6039132  0.6014029\n",
      " 0.614421   0.61325926 0.6114429  0.60952276 0.61415446 0.6127305\n",
      " 0.6216098  0.60522723 0.60863465 0.6100095  0.6219999  0.61188245\n",
      " 0.6116677  0.60754293 0.6094993  0.6113127  0.6073763  0.6053808\n",
      " 0.61207235 0.61254764 0.6158874  0.6234371  0.6098403  0.6101206\n",
      " 0.61129373 0.62037575 0.61172706 0.6117749  0.61252576 0.6067425\n",
      " 0.60644364 0.61148    0.6028615  0.61346847 0.6066234  0.61971736\n",
      " 0.6135782  0.6125244  0.60754126 0.6051288  0.61203516 0.6142294\n",
      " 0.610478   0.6143532  0.61021286 0.6117513  0.60851705 0.61217487\n",
      " 0.61083233 0.61402327 0.6119733  0.61485666 0.6079885  0.60776365]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test).flatten()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d378f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab90216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ce2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
